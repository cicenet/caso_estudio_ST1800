{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "# make sure pyspark tells workers to use python3 not 2 if both are installed\n",
    "#os.environ['PYSPARK_PYTHON'] = '/home/ubuntu/anaconda3/bin/python3'\n",
    "#os.environ['PYSPARK_DRIVER_PYTHON'] = '/home/ubuntu/anaconda3/bin/ipython'\n",
    "#!pip install metapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.linalg import Vectors\n",
    "import pyspark\n",
    "from pyspark.sql import SQLContext\n",
    "import metapy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Al ejecutar esta celda se demora un poco, así que un poco de paciencia\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "sc = SparkContext('local', \"news_cleaned_topic_model\") \n",
    "spark = SparkSession(sc)\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------------+--------------+--------------------+----------+------+-----+----+--------------------+\n",
      "| id|id_news|               title|   publication|              author|      date|  year|month| url|             content|\n",
      "+---+-------+--------------------+--------------+--------------------+----------+------+-----+----+--------------------+\n",
      "|  0|  17283|House Republicans...|New York Times|          Carl Hulse|2016-12-31|2016.0| 12.0|null|WASHINGTON  —   C...|\n",
      "|  1|  17284|Rift Between Offi...|New York Times|Benjamin Mueller ...|2017-06-19|2017.0|  6.0|null|After the bullet ...|\n",
      "|  2|  17285|Tyrus Wong, ‘Bamb...|New York Times|        Margalit Fox|2017-01-06|2017.0|  1.0|null|When Walt Disney’...|\n",
      "|  3|  17286|Among Deaths in 2...|New York Times|    William McDonald|2017-04-10|2017.0|  4.0|null|Death may be the ...|\n",
      "|  4|  17287|Kim Jong-un Says ...|New York Times|       Choe Sang-Hun|2017-01-02|2017.0|  1.0|null|SEOUL, South Kore...|\n",
      "|  5|  17288|Sick With a Cold,...|New York Times|         Sewell Chan|2017-01-02|2017.0|  1.0|null|LONDON  —   Queen...|\n",
      "|  6|  17289|Taiwan’s Presiden...|New York Times| Javier C. Hernández|2017-01-02|2017.0|  1.0|null|BEIJING  —   Pres...|\n",
      "|  7|  17290|After ‘The Bigges...|New York Times|         Gina Kolata|2017-02-08|2017.0|  2.0|null|Danny Cahill stoo...|\n",
      "|  8|  17291|First, a Mixtape....|New York Times|    Katherine Rosman|2016-12-31|2016.0| 12.0|null|Just how   is Hil...|\n",
      "|  9|  17292|Calling on Angels...|New York Times|         Andy Newman|2016-12-31|2016.0| 12.0|null|Angels are everyw...|\n",
      "+---+-------+--------------------+--------------+--------------------+----------+------+-----+----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfNews=spark.read.csv(\"file:///home/ubuntu/Caso_estudio/datasets/news.csv\", inferSchema=True, header=True, encoding=\"UTF-8\")\n",
    "dfNews.show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis Descriptivo del Dataset de Noticias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNews.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNewsFiltered=dfNews.na.drop(subset=(\"title\",\"publication\",\"author\",\"year\", \"date\", \"month\",\"content\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNewsFiltered.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPublishers=dfNewsFiltered.select(\"publication\",\"year\", \"date\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcountPublications=pd.value_counts(dfPublishers['publication'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSummary=dfcountPublications[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfSummary.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import codecs\n",
    "#import matplotlib.pyplot as plt\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "nltk.download(['stopwords'])\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMainCols= dfNewsFiltered.select('id_news','title','publication','content')\n",
    "dfMainCols.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conteo de las palabras iniciales que están en el título y del contenido de la noticia\n",
    "def countWords(record):\n",
    "    textTitle  = record[1]\n",
    "    textContent = record[3]\n",
    "    textCombined = textTitle + \" \" + textContent\n",
    "    words = textCombined.split()\n",
    "    longitudTexto=len(words)\n",
    "    return longitudTexto\n",
    "\n",
    "udf_countWords = udf(countWords, IntegerType())\n",
    "dfcountWords = dfMainCols.withColumn(\"countWords\", udf_countWords(struct([dfMainCols[x] for x in dfMainCols.columns])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, CountVectorizer\n",
    "from pyspark.ml.linalg import Vectors, SparseVector\n",
    "from pyspark.ml.clustering import LDA, BisectingKMeans\n",
    "#from pyspark.sql.functions import monotonically_increasing_id\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total de palabras del título y de la descripción de los artículos\n",
    "totalWords = dfcountWords.agg(F.sum(\"countWords\")).collect()\n",
    "totalWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#publishers= dfMainCols.select(\"publication\").distinct()\n",
    "#publishers.show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default list of Stopwords\n",
    "\n",
    "stopWords1 = stopwords.words('english')\n",
    "\n",
    "stopwords2 = [word.lower() for word in stopWords1] \n",
    "\n",
    "stopwords_custom = ['New', 'York','Times','Breitbart', 'News', 'Daily', 'NPR','Reuters','Guardian','CNN','Atlantic','Vox']\n",
    "stopwords3 = stopwords2 + stopwords_custom\n",
    "\n",
    "#Stemmer\n",
    "ps = PorterStemmer() \n",
    "\n",
    "def cleanup_text(record):\n",
    "    textTitle  = str(record[1])\n",
    "    textPublication=str(record[2])\n",
    "    textContent = str(record[3])\n",
    "    \n",
    "    #setStopwordsCustom =set(stopwords_custom)\n",
    "    #setStopwordsCustom =setStopwordsCustom.union(set(textPublication.split()))\n",
    "    #stopwords_custom1 = list(setStopwordsCustom)\n",
    "    #stopwords_custom= stopwords_custom1\n",
    "    #stopwords = stopwords_core + stopwords_custom1\n",
    "    #title=textTitle\n",
    "    #longPublication =len(textPublication) # Calcular la longitud de la cadena de caracteres  del publisher de la noticia\n",
    "    #longTitle=len(textTitle)  # Calcular la longitud de la cadena del titulo de la noticia\n",
    "    \n",
    "    #if longTitle > longPublication:\n",
    "    #    textPublisher=textTitle[longTitle-longPublication-1:longTitle] # Extrar caracteres derechos del titulo\n",
    "    #    if textPublisher==textPublication:\n",
    "    #        title=textTitle[0:longTitle-longPublication-1]\n",
    "    #    else:\n",
    "    #        title=textTitle\n",
    "    \n",
    "    textCombined = textTitle + \" \" + textContent\n",
    "    # Remove special characters\n",
    "    textCombined= re.sub('(-|-|\\u2212|\\u2012|\\u2013|\\u2014|\\u2015)\\n','',textCombined)\n",
    "    textCombined= re.sub('(-|-|\\u2212|\\u2012|\\u2013|\\u2014|\\u2015)',' ',textCombined)\n",
    "    textCombined= re.sub('[^(a-zA-Z)]',' ',textCombined)\n",
    "    textCombined= re.sub(' +',' ',textCombined)\n",
    "    words = textCombined.split()\n",
    "    tokens3 = [word.lower() for word in words if len(word)>3 and word.lower() not in stopwords3] \n",
    "    text_out = [ps.stem(w) for w in tokens3]\n",
    "    \n",
    "    #text_out = [re.sub('(-|-|\\u2212|\\u2012|\\u2013|\\u2014|\\u2015)\\n','',word) for word in words]\n",
    "    #text_out = [re.sub('(-|-|\\u2212|\\u2012|\\u2013|\\u2014|\\u2015)',' ',word) for word in words]\n",
    "    #text_out = [re.sub('[^(a-zA-Z)]',' ',word) for word in words]                                   \n",
    "    #text_out = [re.sub(' +',' ',word) for word in words] \n",
    "    # Remove stopwords and words under X length\n",
    "    return text_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf_cleantext = udf(cleanup_text , ArrayType(StringType()))\n",
    "dfCombined = dfMainCols.withColumn(\"CombinedTokens\", udf_cleantext(struct([dfMainCols[x] for x in dfMainCols.columns])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCombined.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countTokens(record):\n",
    "    listTokens = record[4]\n",
    "    #words = textTitle.split(\",\")\n",
    "    numTokens=len(listTokens)\n",
    "    return numTokens\n",
    "\n",
    "udf_countTokens = udf(countTokens, IntegerType())\n",
    "dfcountTokens = dfCombined.withColumn(\"countTokens\", udf_countTokens(struct([dfCombined[x] for x in dfCombined.columns])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcountTokens.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalTokens = dfcountTokens.agg(F.sum(\"countTokens\")).collect()\n",
    "totalTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfvocab=dfCombined.select(\"CombinedTokens\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabNews = set()\n",
    "fil,col=dfvocab.shape\n",
    "#print(\"Dimensiones de filas {} y de columnas {} de dataframe\".format(fil,col))\n",
    "#in workVoc.iloc[:,0]:\n",
    "for i in range(fil): \n",
    "    vocabNews = vocabNews.union(set(dfvocab.iloc[i,0]))\n",
    "len(vocabNews)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
